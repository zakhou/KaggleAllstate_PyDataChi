{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cracking the Kaggle Competition#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Allstate Claims Severity\n",
    "\n",
    "[https://www.kaggle.com/c/allstate-claims-severity](https://www.kaggle.com/c/allstate-claims-severity)\n",
    "<img src=\"./figures/allstate_front.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation Scheme\n",
    "* [Mean absolute error](https://www.kaggle.com/c/allstate-claims-severity/details/evaluation)\n",
    "$$\\mathrm{MAE} = \\frac{1}{n}\\sum_1^n \\lvert y_i - y_{i,0} \\rvert$$\n",
    "    * Different from the default evaluation/loss function that\n",
    "$$\\mathrm{rmse} = \\sqrt{\\frac{1}{n}\\sum_1^n \\left( y_i - y_{i,0} \\right)^2}$$\n",
    "    * Estimate of the median instead of the mean of the predicted target distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Leaderboard Ranking\n",
    "* Public Leaderboard\n",
    "* Private Leaderboard\n",
    "* Small improvement probably leads to HUGE boost on leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dataset\n",
    "[https://www.kaggle.com/c/allstate-claims-severity/data](https://www.kaggle.com/c/allstate-claims-severity/data)\n",
    "* csv format for both training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((188318, 132), (125546, 131))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9   ...        cont6  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B   ...     0.718367   \n",
       "1   2    A    B    A    A    A    A    A    A    B   ...     0.438917   \n",
       "2   5    A    B    A    A    B    A    A    A    B   ...     0.289648   \n",
       "3  10    B    B    A    B    A    A    A    A    B   ...     0.440945   \n",
       "4  11    A    B    A    B    A    A    A    A    B   ...     0.178193   \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0  0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "1  0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "2  0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "3  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "4  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "\n",
       "     cont14     loss  \n",
       "0  0.714843  2213.18  \n",
       "1  0.304496  1283.60  \n",
       "2  0.774425  3005.09  \n",
       "3  0.602642   939.85  \n",
       "4  0.432606  2763.85  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['loss'] = np.nan\n",
    "df_train_test = train.append(test, ignore_index)\n",
    "df_train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7',\n",
       "       'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14',\n",
       "       'cat15', 'cat16', 'cat17', 'cat18', 'cat19', 'cat20', 'cat21',\n",
       "       'cat22', 'cat23', 'cat24', 'cat25', 'cat26', 'cat27', 'cat28',\n",
       "       'cat29', 'cat30', 'cat31', 'cat32', 'cat33', 'cat34', 'cat35',\n",
       "       'cat36', 'cat37', 'cat38', 'cat39', 'cat40', 'cat41', 'cat42',\n",
       "       'cat43', 'cat44', 'cat45', 'cat46', 'cat47', 'cat48', 'cat49',\n",
       "       'cat50', 'cat51', 'cat52', 'cat53', 'cat54', 'cat55', 'cat56',\n",
       "       'cat57', 'cat58', 'cat59', 'cat60', 'cat61', 'cat62', 'cat63',\n",
       "       'cat64', 'cat65', 'cat66', 'cat67', 'cat68', 'cat69', 'cat70',\n",
       "       'cat71', 'cat72', 'cat73', 'cat74', 'cat75', 'cat76', 'cat77',\n",
       "       'cat78', 'cat79', 'cat80', 'cat81', 'cat82', 'cat83', 'cat84',\n",
       "       'cat85', 'cat86', 'cat87', 'cat88', 'cat89', 'cat90', 'cat91',\n",
       "       'cat92', 'cat93', 'cat94', 'cat95', 'cat96', 'cat97', 'cat98',\n",
       "       'cat99', 'cat100', 'cat101', 'cat102', 'cat103', 'cat104', 'cat105',\n",
       "       'cat106', 'cat107', 'cat108', 'cat109', 'cat110', 'cat111',\n",
       "       'cat112', 'cat113', 'cat114', 'cat115', 'cat116', 'cont1', 'cont2',\n",
       "       'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9',\n",
       "       'cont10', 'cont11', 'cont12', 'cont13', 'cont14', 'loss'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "features_categorical = []\n",
    "features_numeric = []\n",
    "for f in train.columns:\n",
    "    if 'cat' in f:\n",
    "        features_categorical.append(f)\n",
    "    elif 'cont' in f:\n",
    "        features_numeric.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Properties of train/test dataset\n",
    "* No missing value\n",
    "* 116 categorical features coded by alphabets\n",
    "* 14 numeric features\n",
    "* 1 target column \"loss\"\n",
    "* 188,318 claims in training data\n",
    "* 125,546 claims in test data (to be predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Engineering\n",
    "* Limited by anonymous feature names\n",
    "* \"Blind\" feature engineering\n",
    "* Separate categorical and numeric features\n",
    "* Add new features based on numerical properties of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Categorical Features\n",
    "* Overview of the categorical features\n",
    "* Processing/Encoding categorical features\n",
    "* Add new categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview of the Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat1 category counts\n",
      "A    141550\n",
      "B     46768\n",
      "Name: cat1, dtype: int64\n",
      "------\n",
      "cat80 category counts\n",
      "D    137505\n",
      "B     46538\n",
      "C      3492\n",
      "A       783\n",
      "Name: cat80, dtype: int64\n",
      "------\n",
      "cat111 category counts\n",
      "A    128395\n",
      "C     32401\n",
      "E     14682\n",
      "G      7039\n",
      "I      3578\n",
      "K      1353\n",
      "M       473\n",
      "O       221\n",
      "Q        91\n",
      "S        38\n",
      "W        16\n",
      "U        16\n",
      "B         7\n",
      "D         3\n",
      "F         3\n",
      "Y         2\n",
      "Name: cat111, dtype: int64\n",
      "------\n",
      "cat112 category counts\n",
      "E     25148\n",
      "AH    18639\n",
      "AS    17669\n",
      "J     16222\n",
      "AF     9368\n",
      "AN     9138\n",
      "N      8453\n",
      "U      8356\n",
      "AV     7122\n",
      "AK     6726\n",
      "K      6059\n",
      "AI     4749\n",
      "S      4201\n",
      "AP     4000\n",
      "G      3168\n",
      "F      3149\n",
      "AW     3145\n",
      "A      2411\n",
      "AR     2365\n",
      "C      2257\n",
      "O      2183\n",
      "D      1645\n",
      "AD     1531\n",
      "AY     1414\n",
      "Y      1351\n",
      "AG     1331\n",
      "AT     1272\n",
      "AA     1241\n",
      "AM     1170\n",
      "AL     1130\n",
      "R      1123\n",
      "AX     1074\n",
      "I       940\n",
      "X       925\n",
      "AE      834\n",
      "Q       793\n",
      "V       693\n",
      "H       548\n",
      "AO      534\n",
      "T       521\n",
      "L       493\n",
      "W       461\n",
      "AC      454\n",
      "M       439\n",
      "AU      434\n",
      "B       423\n",
      "P       406\n",
      "AB      246\n",
      "BA      190\n",
      "AJ      144\n",
      "AQ       30\n",
      "Name: cat112, dtype: int64\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "cat_names = ['cat1', 'cat80', 'cat111','cat112']\n",
    "for c in cat_names:\n",
    "    print c+\" category counts\"\n",
    "    print train[c].value_counts()\n",
    "    print \"------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Categorical Features\n",
    "* Factorize Encoding\n",
    "    * Not quite meaningful for a regression problem (especially for linear regression)\n",
    "    * biased difference between categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def prezero(char):\n",
    "    if len(char) == 1: return '0'+char \n",
    "    else: return char\n",
    "\n",
    "train_ = train.copy()\n",
    "train_cat_factorize = pd.DataFrame()\n",
    "\n",
    "for f in features_categorical:\n",
    "    train[f] = train[f].apply(prezero)\n",
    "    train_cat_factorize[f] = pd.factorize(train[f], sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat1_factorize</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat113_factorize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>BM</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>AF</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>AE</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>BM</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1  cat1_factorize cat113  cat113_factorize\n",
       "0    A               0      S                16\n",
       "1    A               0     BM                58\n",
       "2    A               0     AF                26\n",
       "3    B               1     AE                25\n",
       "4    A               0     BM                58"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_names = ['cat1', 'cat113']\n",
    "df = pd.DataFrame()\n",
    "for c in cat_names:\n",
    "    df[c] = train_[c]\n",
    "    df[c+'_factorize'] = train_cat_factorize[c]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Categorical Features\n",
    "* One Hot Encoding - convert categories within one column to multiple columns of booleans of categories\n",
    "    * More rational\n",
    "    * Increase the dimension of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train_cat_ohe = pd.DataFrame()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "tmp = ohe.fit_transform(train_cat_factorize)\n",
    "\n",
    "for f, (i,j) in zip(features_categorical, zip(ohe.feature_indices_[0:],ohe.feature_indices_[1:])):\n",
    "    cat_values = np.sort(train_[f].unique())\n",
    "    for c, k in zip(cat_values, range(i,j)):\n",
    "        train_cat_ohe[f+'_'+c] = tmp[:,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_cat_dummy = pd.get_dummies(train[features_categorical], prefix=features_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat80</th>\n",
       "      <th>cat80_0A</th>\n",
       "      <th>cat80_0B</th>\n",
       "      <th>cat80_0C</th>\n",
       "      <th>cat80_0D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat80  cat80_0A  cat80_0B  cat80_0C  cat80_0D\n",
       "0     D       0.0       0.0       0.0       1.0\n",
       "1     D       0.0       0.0       0.0       1.0\n",
       "2     B       0.0       1.0       0.0       0.0\n",
       "3     D       0.0       0.0       0.0       1.0\n",
       "4     B       0.0       1.0       0.0       0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 'cat80'\n",
    "df = pd.DataFrame()\n",
    "df[c] = train_[c]\n",
    "for f in train_cat_dummy.columns:\n",
    "    if c in f:\n",
    "        df[f] = train_cat_dummy[f]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Target Mean Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/univariate_cat113.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/33.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Target Mean Encoding\n",
    "    * Based on target outcome (mean values) for individual categories in each feature\n",
    "    * Shed light on categorical features more correlated with target\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/univariate_cat113_target_sorted.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/35.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Add New Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Numeric Features\n",
    "* Overview of the numeric features\n",
    "* Processing/Regularizing numeric features\n",
    "* Add new numeric features based on feature correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview of the numeric features\n",
    "* All numeric features with values $\\in [0,1]$\n",
    "* Strong correlation between several pairs of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./figures/numeric_scatter.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Processing numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* BoxCox if skewness $> 0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox, skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for f in features_numeric:\n",
    "    if skew(df_train_test.loc[:num_train, f].values) > 0.25:\n",
    "        df_train_test[f], lam = boxcox(df_train_test[f]+1.00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "for f in features_numeric:\n",
    "    df_train_test[f] = ss.fit_transform(df_train_test[f].values.reshape(-1,1).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Add New Numeric Features\n",
    "* Based on the correlation between pairs of features\n",
    "* Pearson correlation map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/correlation.svg\" width=\"800\" />](https://plot.ly/~zhenhou/37.embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cmap = df_train_test.loc[:num_train, features_numeric].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictive Modeling\n",
    "* Cross-Validation (K-Folds)\n",
    "* Gradient Boosting Machine (xgboost)\n",
    "* Multi-Layer Perceptron Neural Network (keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "* KFolds - regression\n",
    "* StratifiedKFolds - classification\n",
    "* StratifiedKFolds for regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### RegStratifiedKFolds\n",
    "* Make the target distributions of CV-train/CV-test more close between folds\n",
    "* Reduce the variance of the CV-score between folds\n",
    "* 23% improvement on the variance based on tests with n_folds=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import _BaseKFold\n",
    "from sklearn.utils.validation import check_random_state\n",
    "import numpy as np\n",
    "\n",
    "class RegStratifiedKFold(_BaseKFold):\n",
    "    def __init__(self, y, n_folds=5, shuffle=False, random_state=None):\n",
    "        super(RegStratifiedKFold, self).__init__(len(y), n_folds=n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        ylen = len(y)\n",
    "        if ylen / n_folds <= 1:\n",
    "            print \"Too few elements in y. Still in ToDo list\"\n",
    "            exit()\n",
    "        y_index = np.arange(ylen)[np.argsort(y)]\n",
    "        num_classes = ylen / n_folds + int(ylen % n_folds != 0)\n",
    "        \n",
    "        num_head_tail_classes = n_folds * (ylen / n_folds / 2)\n",
    "        head_classes = y_index[0:num_head_tail_classes].reshape(-1,n_folds)\n",
    "        tail_classes = y_index[-num_head_tail_classes:].reshape(-1,n_folds)\n",
    "        \n",
    "        middle_class = y_index[num_head_tail_classes:-num_head_tail_classes] \n",
    "        middle_class = np.hstack([middle_class, -np.ones(n_folds - len(middle_class) % n_folds, dtype=int)])\n",
    "        middle_class = middle_class.reshape(-1,n_folds)\n",
    "        \n",
    "        test_masks = np.vstack([head_classes, middle_class, tail_classes])\n",
    "        self._test_masks = []\n",
    "        \n",
    "        if shuffle:\n",
    "            rng = check_random_state(self.random_state)\n",
    "            for cls in test_masks:\n",
    "                rng.shuffle(cls)\n",
    "                self._test_masks.append(cls.tolist())\n",
    "        else:\n",
    "            self._test_masks = test_masks\n",
    "            \n",
    "        self._test_masks = np.array(self._test_masks).T\n",
    "        self._test_masks = [y[y!=-1] for y in self._test_masks]\n",
    "        \n",
    "    def _iter_test_masks(self):\n",
    "        indarr = np.zeros( self.n, dtype = bool)\n",
    "        for mask in self._test_masks:\n",
    "            indarr[:] = False\n",
    "            indarr[mask] = True \n",
    "            yield indarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## XGBoost\n",
    "[https://github.com/dmlc/xgboost/blob/master/doc/parameter.md](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md)\n",
    "* General Parameters\n",
    "    * booster [default='gbtree']\n",
    "    * num_boost_rounds\n",
    "* Training Parameters\n",
    "    * objective [default='reg:linear']\n",
    "    * eval_metric\n",
    "    * early_stopping_rounds\n",
    "    * seed\n",
    "* Model Parameters\n",
    "    * max_depth [default=6]\n",
    "    * min_child_weight [default=1]\n",
    "    * gamma [default=1]\n",
    "    * colsample_bytree [default=1]\n",
    "    * subsample [default=1]\n",
    "    * alpha [default=0]\n",
    "    * lambda [default=1]\n",
    "    * eta [default=0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First XGBoost Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "\n",
    "import xgboost\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "run_type = 'MAE+ContReg+CatCoadd'\n",
    "\n",
    "train_file = './data/train_'+run_type+'.hdf5'\n",
    "test_file  = './data/test_'+run_type+'.hdf5'\n",
    "\n",
    "train  = pd.read_hdf(train_file)\n",
    "test   = pd.read_hdf(test_file)\n",
    "target = train['loss'].values\n",
    "train.drop('loss', axis=1, inplace=True)\n",
    "\n",
    "params = {'objective':'reg:linear',\n",
    "          'booster': 'gbtree',\n",
    "          'eval_metric': 'mae',\n",
    "          'max_depth': 10,\n",
    "          'seed': 2016,\n",
    "          'eta':0.03}\n",
    "\n",
    "evals_result = []\n",
    "\n",
    "kf = KFold(train.shape[0], n_folds=5, shuffle=True, random_state=2016)\n",
    "for i, (train_index, test_index) in enumerate(kf):\n",
    "    train_target_fold = target[train_index]\n",
    "    test_target_fold  = target[test_index]\n",
    "\n",
    "    dtrain   = xgboost.DMatrix(train.iloc[train_index], label=train_target_fold)\n",
    "    dtest_cv = xgboost.DMatrix(train.iloc[test_index], label=test_target_fold)\n",
    "\n",
    "    evals = [(dtrain,'train'), (dtest_cv,'test')] \n",
    "    evals_result_fold = {}\n",
    "\n",
    "    xgb_train = xgboost.train(params, dtrain, num_boost_round=5000, evals=evals, evals_result=evals_result_fold)\n",
    "    evals_result.append(evals_result_fold)\n",
    "\n",
    "with open('./outputs/first_xgboost_5_KFolds.pkl', 'wb') as fp:\n",
    "    pkl.dump(evals_result, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/first_xgboost.svg\" width=\"800\" />](https://plot.ly/~zhenhou/39.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Over-fitting\n",
    "* Improvements? Optimizations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Objective/Loss Function\n",
    "* XGBoost default = rmse\n",
    "* Customized objective function for XGBoost\n",
    "    * [Examples of loss functions for regression](http://research.microsoft.com/en-us/um/people/zhang/INRIA/Publis/Tutorial-Estim/node24.html)\n",
    "        * \"Fair\" function\n",
    "            $$\\rho(x) = c^2\\left[\\frac{\\lvert x \\rvert}{c} - \\log (1+\\frac{\\lvert x \\rvert}{c})\\right]$$\n",
    "            * Numerical stability\n",
    "            * Nicely converging procedures\n",
    "            * One free parameter $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Target Transformation\n",
    "* Target (insurance claim) distribution in training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/target.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/20.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $y \\rightarrow y' = \\log(y+a)$\n",
    "* $y \\rightarrow y' = y^b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/target_transformed.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/22.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* We choose logarithm transformation with one free parameter $a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parameter tuning\n",
    "[http://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html](http://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html)\n",
    "* RegStratifiedKfold with n_folds = 10\n",
    "* $\\{a, \\ c, \\ \\mathrm{max\\_depth},\\ \\mathrm{min\\_child\\_weight}, \\ \\mathrm{gamma}, \\ \\mathrm{colsample\\_bytree}, \\ \\mathrm{subsample}, \\ \\mathrm{alpha}, \\ \\mathrm{lambda}, \\ \\mathrm{eta}\\}$\n",
    "* 10 sub-models to tune with $\\mathrm{max\\_depth} = \\{8,9,10,11,12\\}$ and $\\mathrm{gamma} = \\{0,1\\}$\n",
    "* Tuning other 8 parameters for each sub-model\n",
    "* Hierarchical tuning scheme\n",
    "    * $\\{a, \\ c, \\ \\mathrm{min\\_child\\_weight}, \\ \\mathrm{colsample\\_bytree}\\}$\n",
    "    * $\\{\\mathrm{subsample}, \\ \\mathrm{alpha}, \\ \\mathrm{lambda}\\}$\n",
    "    * reduce $\\mathrm{eta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parameter tuning\n",
    "* Stage0 - Very beginning\n",
    "* Stage1 - Coarse grid search in $\\{a, \\ c, \\ \\mathrm{min\\_child\\_weight}, \\ \\mathrm{colsample\\_bytree}\\}$\n",
    "* Stage2 - Finer grid search in $\\{a, \\ c, \\ \\mathrm{min\\_child\\_weight}, \\ \\mathrm{colsample\\_bytree}\\}$\n",
    "* Stage3 - Further finer grid search in $\\{a, \\ c, \\ \\mathrm{min\\_child\\_weight}, \\ \\mathrm{subsample}\\}$\n",
    "* Stage4 - Final grid search in $\\{\\mathrm{alpha}, \\ \\mathrm{lambda}\\}$\n",
    "* Stage5 - Reduce $\\mathrm{eta}$\n",
    "* Stage6 - Linear combination for each $\\mathrm{max\\_depth}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/parameter_tuning_xgboost.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/41.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Improvements beyond the Default\n",
    "\n",
    "* Target encoding categorical features (XGBoost)\n",
    "* Adding new features, both categorical and numeric\n",
    "* Stratified KFolds for regression\n",
    "* Customized objective function with one free parameter\n",
    "* Target transformation with one free parameter\n",
    "* XGBoost parameters tuning along with two additional nuisance parameters (above)\n",
    "* Bagging/Bootstrapping for MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Things not quite helpful\n",
    "\n",
    "* One Hot Encoding for XGBoost\n",
    "* Target encoding categorical features for MLP\n",
    "* PCA numeric features for XGBoost\n",
    "* PCA encoded categorical features for XGBoost"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
