{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<pre><code>\n",
    "git clone git@github.com:zakhou/KaggleAllstate_PyDataChi.git\n",
    "\n",
    "cd KaggleAllstate_PyDataChi\n",
    "\n",
    "jupyter nbconvert KaggleAllstate_PyDataChi.ipynb --to slides --reveal-prefix=reveal.js\n",
    "</code></pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cracking the Kaggle Competition\n",
    "## Allstate Claims Severity\n",
    "\n",
    "Zak Hou <br>\n",
    "zak@zakhou.com <br>\n",
    "@ZakzHou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "* Overview of the competition and the dataset\n",
    "* Feature engineering\n",
    "* Predictive modeling\n",
    "* Ensemble models\n",
    "* Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Allstate Claims Severity\n",
    "\n",
    "[https://www.kaggle.com/c/allstate-claims-severity](https://www.kaggle.com/c/allstate-claims-severity)\n",
    "<img src=\"./figures/allstate_front.png\" width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation Scheme\n",
    "* [Mean absolute error](https://www.kaggle.com/c/allstate-claims-severity/details/evaluation)\n",
    "$$\\mathrm{MAE} = \\frac{1}{n}\\sum_1^n \\lvert y_i - y_{i,0} \\rvert$$\n",
    "    * Different from the default evaluation/loss function that\n",
    "$$\\mathrm{rmse} = \\sqrt{\\frac{1}{n}\\sum_1^n \\left( y_i - y_{i,0} \\right)^2}$$\n",
    "    * Estimate of the median instead of the mean of the predicted target distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Leaderboard Ranking\n",
    "* Public Leaderboard\n",
    "* Private Leaderboard\n",
    "* Small improvement probably leads to HUGE boost on leaderboard\n",
    "    * Top 10  1110.69997\n",
    "    * Top 1%  1112.34516\n",
    "    * Top 2%  1112.98348\n",
    "    * Top 5%  1113.98717\n",
    "    * Top 10% 1115.55861\n",
    "    * Top 25% 1124.19659\n",
    "    * Top 50% 1138.32473\n",
    "* Leaderboard scores are slightly different from CV scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dataset\n",
    "[https://www.kaggle.com/c/allstate-claims-severity/data](https://www.kaggle.com/c/allstate-claims-severity/data)\n",
    "* csv format for both training and test datasets\n",
    "* Feature/Column names are anonymous\n",
    "    * 'cat' for categorical\n",
    "    * 'cont' for numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((188318, 132), (125546, 131))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9   ...        cont6  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B   ...     0.718367   \n",
       "1   2    A    B    A    A    A    A    A    A    B   ...     0.438917   \n",
       "2   5    A    B    A    A    B    A    A    A    B   ...     0.289648   \n",
       "3  10    B    B    A    B    A    A    A    A    B   ...     0.440945   \n",
       "4  11    A    B    A    B    A    A    A    A    B   ...     0.178193   \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0  0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "1  0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "2  0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "3  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "4  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "\n",
       "     cont14     loss  \n",
       "0  0.714843  2213.18  \n",
       "1  0.304496  1283.60  \n",
       "2  0.774425  3005.09  \n",
       "3  0.602642   939.85  \n",
       "4  0.432606  2763.85  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['loss'] = np.nan\n",
    "df_train_test = train.append(test, ignore_index)\n",
    "df_train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7',\n",
       "       'cat8', 'cat9', 'cat10', 'cat11', 'cat12', 'cat13', 'cat14',\n",
       "       'cat15', 'cat16', 'cat17', 'cat18', 'cat19', 'cat20', 'cat21',\n",
       "       'cat22', 'cat23', 'cat24', 'cat25', 'cat26', 'cat27', 'cat28',\n",
       "       'cat29', 'cat30', 'cat31', 'cat32', 'cat33', 'cat34', 'cat35',\n",
       "       'cat36', 'cat37', 'cat38', 'cat39', 'cat40', 'cat41', 'cat42',\n",
       "       'cat43', 'cat44', 'cat45', 'cat46', 'cat47', 'cat48', 'cat49',\n",
       "       'cat50', 'cat51', 'cat52', 'cat53', 'cat54', 'cat55', 'cat56',\n",
       "       'cat57', 'cat58', 'cat59', 'cat60', 'cat61', 'cat62', 'cat63',\n",
       "       'cat64', 'cat65', 'cat66', 'cat67', 'cat68', 'cat69', 'cat70',\n",
       "       'cat71', 'cat72', 'cat73', 'cat74', 'cat75', 'cat76', 'cat77',\n",
       "       'cat78', 'cat79', 'cat80', 'cat81', 'cat82', 'cat83', 'cat84',\n",
       "       'cat85', 'cat86', 'cat87', 'cat88', 'cat89', 'cat90', 'cat91',\n",
       "       'cat92', 'cat93', 'cat94', 'cat95', 'cat96', 'cat97', 'cat98',\n",
       "       'cat99', 'cat100', 'cat101', 'cat102', 'cat103', 'cat104', 'cat105',\n",
       "       'cat106', 'cat107', 'cat108', 'cat109', 'cat110', 'cat111',\n",
       "       'cat112', 'cat113', 'cat114', 'cat115', 'cat116', 'cont1', 'cont2',\n",
       "       'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9',\n",
       "       'cont10', 'cont11', 'cont12', 'cont13', 'cont14', 'loss'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "features_categorical = []\n",
    "features_numeric = []\n",
    "for f in train.columns:\n",
    "    if 'cat' in f:\n",
    "        features_categorical.append(f)\n",
    "    elif 'cont' in f:\n",
    "        features_numeric.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Properties of train/test dataset\n",
    "\n",
    "* No missing value\n",
    "* 116 categorical features coded by alphabets\n",
    "* 14 numeric features\n",
    "* 1 target column \"loss\"\n",
    "* 188,318 claims in training data\n",
    "* 125,546 claims in test data (to be predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Engineering\n",
    "* Limited by anonymous feature names\n",
    "* \"Blind\" feature engineering\n",
    "* Separate categorical and numeric features\n",
    "* Add new features based on numerical properties of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Categorical Features\n",
    "* Overview of the categorical features\n",
    "* Processing/Encoding categorical features\n",
    "* Add new categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview of the Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat1 category counts\n",
      "A    141550\n",
      "B     46768\n",
      "Name: cat1, dtype: int64\n",
      "------\n",
      "cat80 category counts\n",
      "D    137505\n",
      "B     46538\n",
      "C      3492\n",
      "A       783\n",
      "Name: cat80, dtype: int64\n",
      "------\n",
      "cat111 category counts\n",
      "A    128395\n",
      "C     32401\n",
      "E     14682\n",
      "G      7039\n",
      "I      3578\n",
      "K      1353\n",
      "M       473\n",
      "O       221\n",
      "Q        91\n",
      "S        38\n",
      "W        16\n",
      "U        16\n",
      "B         7\n",
      "D         3\n",
      "F         3\n",
      "Y         2\n",
      "Name: cat111, dtype: int64\n",
      "------\n",
      "cat112 category counts\n",
      "E     25148\n",
      "AH    18639\n",
      "AS    17669\n",
      "J     16222\n",
      "AF     9368\n",
      "AN     9138\n",
      "N      8453\n",
      "U      8356\n",
      "AV     7122\n",
      "AK     6726\n",
      "K      6059\n",
      "AI     4749\n",
      "S      4201\n",
      "AP     4000\n",
      "G      3168\n",
      "F      3149\n",
      "AW     3145\n",
      "A      2411\n",
      "AR     2365\n",
      "C      2257\n",
      "O      2183\n",
      "D      1645\n",
      "AD     1531\n",
      "AY     1414\n",
      "Y      1351\n",
      "AG     1331\n",
      "AT     1272\n",
      "AA     1241\n",
      "AM     1170\n",
      "AL     1130\n",
      "R      1123\n",
      "AX     1074\n",
      "I       940\n",
      "X       925\n",
      "AE      834\n",
      "Q       793\n",
      "V       693\n",
      "H       548\n",
      "AO      534\n",
      "T       521\n",
      "L       493\n",
      "W       461\n",
      "AC      454\n",
      "M       439\n",
      "AU      434\n",
      "B       423\n",
      "P       406\n",
      "AB      246\n",
      "BA      190\n",
      "AJ      144\n",
      "AQ       30\n",
      "Name: cat112, dtype: int64\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "cat_names = ['cat1', 'cat80', 'cat111','cat112']\n",
    "for c in cat_names:\n",
    "    print c+\" category counts\"\n",
    "    print train[c].value_counts()\n",
    "    print \"------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Categorical Features\n",
    "* Factorize Encoding\n",
    "    * Convert the categories as an enumerated type\n",
    "    * Not quite meaningful for a regression problem (especially for linear regression)\n",
    "    * biased difference between categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def prezero(char):\n",
    "    if len(char) == 1: return '0'+char \n",
    "    else: return char\n",
    "\n",
    "train_ = train.copy()\n",
    "train_cat_factorize = pd.DataFrame()\n",
    "\n",
    "for f in features_categorical:\n",
    "    train[f] = train[f].apply(prezero)\n",
    "    train_cat_factorize[f] = pd.factorize(train[f], sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat1_factorize</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat113_factorize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>BM</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>AF</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>AE</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>BM</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1  cat1_factorize cat113  cat113_factorize\n",
       "0    A               0      S                16\n",
       "1    A               0     BM                58\n",
       "2    A               0     AF                26\n",
       "3    B               1     AE                25\n",
       "4    A               0     BM                58"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_names = ['cat1', 'cat113']\n",
    "df = pd.DataFrame()\n",
    "for c in cat_names:\n",
    "    df[c] = train_[c]\n",
    "    df[c+'_factorize'] = train_cat_factorize[c]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Categorical Features\n",
    "* One Hot Encoding - convert categories within one column to multiple columns of booleans of categories\n",
    "    * Convert single column of categories to multi-column booleans for individual categories\n",
    "    * More rational\n",
    "    * Increase the dimension of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train_cat_ohe = pd.DataFrame()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "tmp = ohe.fit_transform(train_cat_factorize)\n",
    "\n",
    "for f, (i,j) in zip(features_categorical, zip(ohe.feature_indices_[0:],ohe.feature_indices_[1:])):\n",
    "    cat_values = np.sort(train_[f].unique())\n",
    "    for c, k in zip(cat_values, range(i,j)):\n",
    "        train_cat_ohe[f+'_'+c] = tmp[:,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_cat_dummy = pd.get_dummies(train[features_categorical], prefix=features_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat80</th>\n",
       "      <th>cat80_0A</th>\n",
       "      <th>cat80_0B</th>\n",
       "      <th>cat80_0C</th>\n",
       "      <th>cat80_0D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat80  cat80_0A  cat80_0B  cat80_0C  cat80_0D\n",
       "0     D       0.0       0.0       0.0       1.0\n",
       "1     D       0.0       0.0       0.0       1.0\n",
       "2     B       0.0       1.0       0.0       0.0\n",
       "3     D       0.0       0.0       0.0       1.0\n",
       "4     B       0.0       1.0       0.0       0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 'cat80'\n",
    "df = pd.DataFrame()\n",
    "df[c] = train_[c]\n",
    "for f in train_cat_dummy.columns:\n",
    "    if c in f:\n",
    "        df[f] = train_cat_dummy[f]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Target Mean Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/univariate_cat113.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/33.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Target Mean Encoding\n",
    "    * Based on target outcome (mean values) for individual categories in each feature\n",
    "    * Shed light on categorical features more correlated with target\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/univariate_cat113_target_sorted.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/35.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Add New Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Numeric Features\n",
    "* Overview of the numeric features\n",
    "* Processing/Regularizing numeric features\n",
    "* Add new numeric features based on feature correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview of the numeric features\n",
    "* All numeric features with values $\\in [0,1]$\n",
    "* Strong correlation between several pairs of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./figures/numeric_scatter.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Processing numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* BoxCox if skewness $> 0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox, skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for f in features_numeric:\n",
    "    if skew(df_train_test.loc[:num_train, f].values) > 0.25:\n",
    "        df_train_test[f], lam = boxcox(df_train_test[f]+1.00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "for f in features_numeric:\n",
    "    df_train_test[f] = ss.fit_transform(df_train_test[f].values.reshape(-1,1).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Add New Numeric Features\n",
    "* Based on the correlation between pairs of features\n",
    "* Pearson correlation map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/correlation.svg\" width=\"800\" />](https://plot.ly/~zhenhou/37.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Pick up pairs of numeric features with correlation > 0.8\n",
    "* Create new features by taking the residual and the difference of the selected pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictive Modeling\n",
    "* Cross-Validation (K-Folds)\n",
    "* Gradient Boosting Machine (xgboost)\n",
    "* Multi-Layer Perceptron Neural Network (keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cross-Validation\n",
    "* KFold - regression\n",
    "* StratifiedKFold - classification\n",
    "* StratifiedKFold for regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### RegStratifiedKFold\n",
    "* Make the target distributions of CV-train/CV-test more close between folds\n",
    "* Reduce the variance of the CV-score between folds\n",
    "* 23% improvement on the variance based on tests with n_folds=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import _BaseKFold\n",
    "from sklearn.utils.validation import check_random_state\n",
    "import numpy as np\n",
    "\n",
    "class RegStratifiedKFold(_BaseKFold):\n",
    "    def __init__(self, y, n_folds=5, shuffle=False, random_state=None):\n",
    "        super(RegStratifiedKFold, self).__init__(len(y), n_folds=n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        ylen = len(y)\n",
    "        if ylen / n_folds <= 1:\n",
    "            print \"Too few elements in y. Still in ToDo list\"\n",
    "            exit()\n",
    "        y_index = np.arange(ylen)[np.argsort(y)]\n",
    "        num_classes = ylen / n_folds + int(ylen % n_folds != 0)\n",
    "        \n",
    "        num_head_tail_classes = n_folds * (ylen / n_folds / 2)\n",
    "        head_classes = y_index[0:num_head_tail_classes].reshape(-1,n_folds)\n",
    "        tail_classes = y_index[-num_head_tail_classes:].reshape(-1,n_folds)\n",
    "        \n",
    "        middle_class = y_index[num_head_tail_classes:-num_head_tail_classes] \n",
    "        middle_class = np.hstack([middle_class, -np.ones(n_folds - len(middle_class) % n_folds, dtype=int)])\n",
    "        middle_class = middle_class.reshape(-1,n_folds)\n",
    "        \n",
    "        test_masks = np.vstack([head_classes, middle_class, tail_classes])\n",
    "        self._test_masks = []\n",
    "        \n",
    "        if shuffle:\n",
    "            rng = check_random_state(self.random_state)\n",
    "            for cls in test_masks:\n",
    "                rng.shuffle(cls)\n",
    "                self._test_masks.append(cls.tolist())\n",
    "        else:\n",
    "            self._test_masks = test_masks\n",
    "            \n",
    "        self._test_masks = np.array(self._test_masks).T\n",
    "        self._test_masks = [y[y!=-1] for y in self._test_masks]\n",
    "        \n",
    "    def _iter_test_masks(self):\n",
    "        indarr = np.zeros( self.n, dtype = bool)\n",
    "        for mask in self._test_masks:\n",
    "            indarr[:] = False\n",
    "            indarr[mask] = True \n",
    "            yield indarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## XGBoost\n",
    "[https://github.com/dmlc/xgboost/blob/master/doc/parameter.md](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md)\n",
    "* General Parameters\n",
    "    * booster [default='gbtree']\n",
    "    * num_boost_rounds\n",
    "* Training Parameters\n",
    "    * objective [default='reg:linear']\n",
    "    * eval_metric\n",
    "    * early_stopping_rounds\n",
    "    * seed\n",
    "* Model Parameters\n",
    "    * max_depth [default=6]\n",
    "    * min_child_weight [default=1]\n",
    "    * gamma [default=1]\n",
    "    * colsample_bytree [default=1]\n",
    "    * subsample [default=1]\n",
    "    * alpha [default=0]\n",
    "    * lambda [default=1]\n",
    "    * eta [default=0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First XGBoost Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "\n",
    "import xgboost\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "run_type = 'MAE+ContReg+CatCoadd'\n",
    "\n",
    "train_file = './data/train_'+run_type+'.hdf5'\n",
    "test_file  = './data/test_'+run_type+'.hdf5'\n",
    "\n",
    "train  = pd.read_hdf(train_file)\n",
    "test   = pd.read_hdf(test_file)\n",
    "target = train['loss'].values\n",
    "train.drop('loss', axis=1, inplace=True)\n",
    "\n",
    "params = {'objective':'reg:linear',\n",
    "          'booster': 'gbtree',\n",
    "          'eval_metric': 'mae',\n",
    "          'max_depth': 10,\n",
    "          'seed': 2016,\n",
    "          'eta':0.03}\n",
    "\n",
    "evals_result = []\n",
    "\n",
    "kf = KFold(train.shape[0], n_folds=5, shuffle=True, random_state=2016)\n",
    "for i, (train_index, test_index) in enumerate(kf):\n",
    "    train_target_fold = target[train_index]\n",
    "    test_target_fold  = target[test_index]\n",
    "\n",
    "    dtrain   = xgboost.DMatrix(train.iloc[train_index], label=train_target_fold)\n",
    "    dtest_cv = xgboost.DMatrix(train.iloc[test_index], label=test_target_fold)\n",
    "\n",
    "    evals = [(dtrain,'train'), (dtest_cv,'test')] \n",
    "    evals_result_fold = {}\n",
    "\n",
    "    xgb_train = xgboost.train(params, dtrain, num_boost_round=5000, evals=evals, evals_result=evals_result_fold)\n",
    "    evals_result.append(evals_result_fold)\n",
    "\n",
    "with open('./outputs/first_xgboost_5_KFolds.pkl', 'wb') as fp:\n",
    "    pkl.dump(evals_result, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/first_xgboost.svg\" width=\"800\" />](https://plot.ly/~zhenhou/39.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Over-fitting\n",
    "* Improvements? Optimizations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Objective/Loss Function\n",
    "* XGBoost default = rmse\n",
    "* Customized objective function for XGBoost\n",
    "    * [Examples of loss functions for regression](http://research.microsoft.com/en-us/um/people/zhang/INRIA/Publis/Tutorial-Estim/node24.html)\n",
    "        * \"Fair\" function\n",
    "            $$\\rho(x) = c^2\\left[\\frac{\\lvert x \\rvert}{c} - \\log (1+\\frac{\\lvert x \\rvert}{c})\\right]$$\n",
    "            * Numerical stability\n",
    "            * Nicely converging procedures\n",
    "            * One free parameter $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Target Transformation\n",
    "* Target (insurance claim) distribution in training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/target.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/20.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $y \\rightarrow y' = \\log(y+a)$\n",
    "* $y \\rightarrow y' = y^b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/target_transformed.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/22.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* We choose logarithm transformation with one free parameter $a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parameter Tuning\n",
    "[http://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html](http://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html)\n",
    "* RegStratifiedKfold with n_folds = 10\n",
    "* $\\{a, \\ c, \\ \\mathrm{max\\_depth},\\ \\mathrm{min\\_child\\_weight}, \\ \\mathrm{gamma}, \\ \\mathrm{colsample\\_bytree}, \\ \\mathrm{subsample}, \\ \\mathrm{alpha}, \\ \\mathrm{lambda}, \\ \\mathrm{eta}\\}$\n",
    "* 10 sub-models to tune with $\\mathrm{max\\_depth} = \\{8,9,10,11,12\\}$ and $\\mathrm{gamma} = \\{0,1\\}$\n",
    "* Tuning other 8 parameters for each sub-model\n",
    "* Hierarchical tuning scheme\n",
    "    * $\\{a, \\ c, \\ \\mathrm{min\\_child\\_weight}, \\ \\mathrm{colsample\\_bytree}\\}$\n",
    "    * $\\{\\mathrm{subsample}, \\ \\mathrm{alpha}, \\ \\mathrm{lambda}\\}$\n",
    "    * reduce $\\mathrm{eta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parameter Tuning Procedure\n",
    "* Stage0 - Very beginning\n",
    "* Stage1 - Coarse grid search in $\\{a, \\ c, \\ \\mathrm{min\\_child\\_weight}, \\ \\mathrm{colsample\\_bytree}\\}$\n",
    "* Stage2 - Finer grid search in $\\{a, \\ c, \\ \\mathrm{min\\_child\\_weight}, \\ \\mathrm{colsample\\_bytree}\\}$\n",
    "* Stage3 - Further finer grid search in $\\{a, \\ c, \\ \\mathrm{min\\_child\\_weight}, \\ \\mathrm{subsample}\\}$\n",
    "* Stage4 - Final grid search in $\\{\\mathrm{alpha}, \\ \\mathrm{lambda}\\}$\n",
    "* Stage5 - Reduce $\\mathrm{eta}$\n",
    "* Stage6 - Linear combination for each $\\mathrm{max\\_depth}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/parameter_tuning_xgboost.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/41.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### CV Scores after Tuning\n",
    "* One example with \n",
    "    * max_depth = 10\n",
    "    * gamma = 0.0\n",
    "    * a = 204\n",
    "    * c = 0.9\n",
    "    * min_child_weight = 258\n",
    "    * colsample_bytree = 0.1\n",
    "    * subsample = 1.0\n",
    "    * eta = 0.01\n",
    "    * alpha = 1.2\n",
    "    * lambda = 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/scores_xgboost_train_md10g0.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/45.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multi-Layer Perceptron (MLP)\n",
    "[Keras Starter Example](https://www.kaggle.com/mtinti/allstate-claims-severity/keras-starter-with-bagging-1111-84364)\n",
    "* One Hot Encoded categorical features + numerical features\n",
    "* A very incomplete example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "\"\"\"\n",
    "Parameters:\n",
    "n_layers: number of hidden layers for MLP\n",
    "elements[]: how many elements for each hidden layer\n",
    "dropouts[]: drop-out ratio for each hidden layer\n",
    "\n",
    "1 + n_layers**2 free parameters\n",
    "\"\"\"\n",
    "\n",
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        if i==0:\n",
    "            model.add(Dense(elements[i], input_dim = xtrain.shape[1], init='he_normal'))\n",
    "        else:\n",
    "            model.add(Dense(elements[i], init='he_normal'))\n",
    "\n",
    "        model.add(PReLU())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropouts[i]))\n",
    "    \n",
    "    model.add(Dense(1, init='he_normal'))\n",
    "    model.compile(loss = 'mae', optimizer = 'adadelta')\n",
    "    return(model)\n",
    "\n",
    "num_bags = 10\n",
    "for i in range(num_bags):\n",
    "    model = mlp_model()\n",
    "    fit = model.fit_generator(generator = batch_generator(xtr, ytr, 128, True),\n",
    "                              nb_epoch = 100,\n",
    "                              samples_per_epoch = xtr.shape[0],\n",
    "                              verbose = 0)\n",
    "    pred += np.exp(model.predict_generator(generator = batch_generatorp(xte, 800), val_samples = xte.shape[0])[:,0]) - log_shift\n",
    "    pred_test += np.exp(model.predict_generator(generator = batch_generatorp(xtest, 800), val_samples = xtest.shape[0])[:,0]) - log_shift\n",
    "    pred_train += np.exp(model.predict_generator(generator = batch_generatorp(xtr, 800), val_samples = xtr.shape[0])[:,0]) - log_shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Very Coarse Parameter Tuning through CV\n",
    "* n_layers=3, elements=[400,200,50], dropouts=[0.3,0.2,0.2]\n",
    "    * CV-Score = 1130.294\n",
    "* n_layers=3, elements=[500,250,75], dropouts=[0.3,0.2,0.2]\n",
    "    * CV-Score = 1130.952\n",
    "* n_layers=4, elements=[600,200,100,50], dropouts=[0.4,0.2,0.2,0.2]\n",
    "    * CV-Score = 1130.900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ensemble Models\n",
    "\n",
    "* Stage7.a - ensemble of XGBoost sub-models\n",
    "* Stage7.b - ensemble of MLP sub-models\n",
    "* Stage8 - Ensemble of both XGBoost and MLP models\n",
    "* Linear regression of combination parameters with Nelder-Mead minimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[<img src=\"./figures/parameter_tuning_xgboost+mlp.svg\" width=\"1000\" />](https://plot.ly/~zhenhou/47.embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Improvements beyond the Default\n",
    "\n",
    "* Target encoding categorical features (XGBoost)\n",
    "* Adding new features, both categorical and numeric\n",
    "* Stratified KFolds for regression\n",
    "* Customized objective function with one free parameter\n",
    "* Target transformation with one free parameter\n",
    "* XGBoost parameters tuning along with two additional nuisance parameters (above)\n",
    "* Bagging/Bootstrapping for MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Things not quite helpful\n",
    "\n",
    "* One Hot Encoding for XGBoost\n",
    "* Target encoding categorical features for MLP\n",
    "* PCA numeric features for XGBoost\n",
    "* PCA encoded categorical features for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Thoughs on Improvements\n",
    "\n",
    "* Add PCA components as new features\n",
    "* Set up Keras on GPU with more intensive parameter tuning\n",
    "* Other models (sklearn.ensemble):\n",
    "    * RandomForrest Regressor\n",
    "    * ExtraTree Regressor\n",
    "    * Bagging Regressor\n",
    "    * AdaBoost Regressor\n",
    "* Outliers\n",
    "    * Classification\n",
    "* More sophisticated second/third level model ensemble (blending)\n",
    "* Real meaning of features\n",
    "* Bayesian scheme for parameter tuning (MCMC?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Thanks to Civis Analytics for hosting and sponsoring the Pizza!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Thanks to everyone who joins our Meetup event!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Thank you, Stephen Hoover and Safia for helping me going through the presentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Thanks to Kaggle community!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
